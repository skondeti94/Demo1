{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-macos==2.15.0 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.59.3)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.15.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (1.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (2.12.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from datasets) (1.24.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from datasets) (2023.4.0)\n",
      "Requirement already satisfied: aiohttp in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from datasets) (0.15.1)\n",
      "Requirement already satisfied: packaging in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: responses<0.19 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from datasets) (0.13.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: filelock in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: six in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from responses<0.19->datasets) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (2.12.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from datasets) (1.24.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from datasets) (2023.4.0)\n",
      "Requirement already satisfied: aiohttp in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from datasets) (0.15.1)\n",
      "Requirement already satisfied: packaging in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: responses<0.19 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from datasets) (0.13.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: filelock in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: six in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from responses<0.19->datasets) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/sushmamruthakondeti/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Found cached dataset parquet (/Users/sushmamruthakondeti/.cache/huggingface/datasets/HuggingFaceH4___parquet/HuggingFaceH4--ultrafeedback_binarized-2b47754548055ac0/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "369a03cca0604e94a97698c46ba9e62f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wikitext (/Users/sushmamruthakondeti/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf5bb59ee71648f8a56ba0bbdbd4cbb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "set_seed(42)\n",
    "generator(\"The cat jumped over the dog and \",max_length=30, num_return_sequences=5)\n",
    "from transformers import AutoTokenizer, GPT2Model\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilgpt2')\n",
    "inputs = tokenizer(\"The cat jumped over the dog and\",return_tensors=\"tf\")\n",
    "inputs\n",
    "from transformers import TFAutoModelForCausalLM\n",
    "model = TFAutoModelForCausalLM.from_pretrained(\"distilgpt2\")\n",
    "outputs = model.generate(input_ids=inputs[\"input_ids\"],attention_mask=inputs[\"attention_mask\"],max_new_tokens=40,num_return_sequences=5, do_sample=True)\n",
    "tokenizer.batch_decode(outputs)\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"HuggingFaceH4/ultrafeedback_binarized\")\n",
    "dataset\n",
    "tokenizer.pad_token = \"[PAD]\"\n",
    "wikitext = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n",
    "wikitext\n",
    "train_text= wikitext[\"train\"][\"text\"]\n",
    "tokenizer.pad_token = \"[PAD]\"\n",
    "train_encodings = tokenizer(train_text,return_tensors=\"tf\", max_length=128,padding=\"max_length\",truncation=True)\n",
    "from datasets import Dataset\n",
    "train_dataset = Dataset.from_dict(train_encodings)\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer,mlm=False, return_tensors=\"tf\")\n",
    "tf_train_set = model.prepare_tf_dataset(train_dataset,shuffle=True, batch_size=16, collate_fn=data_collator)\n",
    "from transformers import AdamWeightDecay\n",
    "optimizer = AdamWeightDecay(learning_rate=2e-5,weight_decay_rate=0.01)\n",
    "model.compile(optimizer=optimizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2294/2294 [==============================] - 31047s 14s/step - loss: 3.8175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2828471d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=tf_train_set, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 30] Read-only file system: 'new_distillgpt2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39msave_pretrained(\u001b[39m\"\u001b[39m\u001b[39mnew_distillgpt2\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/modeling_tf_utils.py:2395\u001b[0m, in \u001b[0;36mTFPreTrainedModel.save_pretrained\u001b[0;34m(self, save_directory, saved_model, version, push_to_hub, signatures, max_shard_size, create_pr, safe_serialization, token, **kwargs)\u001b[0m\n\u001b[1;32m   2392\u001b[0m     logger\u001b[39m.\u001b[39merror(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProvided path (\u001b[39m\u001b[39m{\u001b[39;00msave_directory\u001b[39m}\u001b[39;00m\u001b[39m) should be a directory, not a file\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   2393\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m-> 2395\u001b[0m os\u001b[39m.\u001b[39mmakedirs(save_directory, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   2397\u001b[0m \u001b[39mif\u001b[39;00m push_to_hub:\n\u001b[1;32m   2398\u001b[0m     commit_message \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mcommit_message\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m<frozen os>:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 30] Read-only file system: 'new_distillgpt2'"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(\"new_distillgpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"/Users/sushmamruthakondeti/Desktop/nlp2/new_distillgpt2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at /Users/sushmamruthakondeti/Desktop/nlp2/new_distillgpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModelForCausalLM.from_pretrained(\"/Users/sushmamruthakondeti/Desktop/nlp2/new_distillgpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at /Users/sushmamruthakondeti/Desktop/nlp2/new_distillgpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The cat jumped over the dog and shot the animal in the head so it could swim away. However, the',\n",
       " 'The cat jumped over the dog and made a noise. She went in and looked back at the water @-',\n",
       " 'The cat jumped over the dog and caught the ground. His teeth were so weak that they required his assistance.',\n",
       " \"The cat jumped over the dog and began to run its feet high. The owner's wife was screaming,\",\n",
       " 'The cat jumped over the dog and fled with a few waterfalls off its top as a result. Upon recovering']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer=AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "from transformers import TFAutoModelForCausalLM\n",
    "model=TFAutoModelForCausalLM.from_pretrained(\"/Users/sushmamruthakondeti/Desktop/nlp2/new_distillgpt2\")\n",
    "inputs=tokenizer(\"The cat jumped over the dog and\",return_tensors=\"tf\")\n",
    "outputs =model.generate(input_ids=inputs[\"input_ids\"],attention_mask=inputs[\"attention_mask\"],max_new_tokens=15,num_return_sequences=5, do_sample=True)\n",
    "tokenizer.batch_decode(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at /Users/sushmamruthakondeti/Desktop/nlp2/new_distillgpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The journey of a lone adventurer in World War I ended the war, after he went down from his post',\n",
       " 'The journey of a lone adventurer on this journey involves making the route of land to the island in between the',\n",
       " 'The journey of a lone adventurer and a thief continues with him. He must become a vampire, an alien',\n",
       " 'The journey of a lone adventurer to a small area of the land has been described and compared to the journey',\n",
       " \"The journey of a lone adventurer's journey was made in the history books : it was the end of\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer=AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "from transformers import TFAutoModelForCausalLM\n",
    "model=TFAutoModelForCausalLM.from_pretrained(\"/Users/sushmamruthakondeti/Desktop/nlp2/new_distillgpt2\")\n",
    "inputs1 = tokenizer(\"The journey of a lone adventurer\", return_tensors=\"tf\")\n",
    "\n",
    "outputs1 =model.generate(input_ids=inputs1[\"input_ids\"],attention_mask=inputs1[\"attention_mask\"],max_new_tokens=15,num_return_sequences=5, do_sample=True)\n",
    "tokenizer.batch_decode(outputs1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['In a distant galaxy, there existed a known system of subgalactic nuclei. This system is composed mostly',\n",
       " 'In a distant galaxy, there existed a star known as the R = 1 @,@ 7,000 @',\n",
       " 'In a distant galaxy, there existed a new galaxy known as Kepler, known as Kepler. This may be due',\n",
       " \"In a distant galaxy, there existed an important group of xenon that lived on xenon's core,\",\n",
       " \"In a distant galaxy, there existed an enormous dark @-@ sky called the Anaconda's @\"]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs2 = tokenizer(\"In a distant galaxy, there existed\", return_tensors=\"tf\")\n",
    "outputs2 =model.generate(input_ids=inputs2[\"input_ids\"],attention_mask=inputs2[\"attention_mask\"],max_new_tokens=15,num_return_sequences=5, do_sample=True)\n",
    "tokenizer.batch_decode(outputs2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Amidst the chaos, a hero emerged. The Redcoat had the most famous scene in an episode of American Family',\n",
       " 'Amidst the chaos, a hero emerged from the wreckage of a shipwreck. The ship sank to the right on',\n",
       " 'Amidst the chaos, a hero emerged from a vast pool of survivors. They began to rebuild, as a city',\n",
       " 'Amidst the chaos, a hero emerged from the ruins of the town and sent thousands towards the town to fight the',\n",
       " 'Amidst the chaos, a hero emerged from the field and threw on a ball thrown by the crowd of over 9']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs3 = tokenizer(\"Amidst the chaos, a hero emerged\", return_tensors=\"tf\")\n",
    "outputs3 =model.generate(input_ids=inputs3[\"input_ids\"],attention_mask=inputs3[\"attention_mask\"],max_new_tokens=15,num_return_sequences=5, do_sample=True)\n",
    "tokenizer.batch_decode(outputs3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['When the moonlight faded, it revealed the moon was actually black. While the moonlight was not exactly white,',\n",
       " \"When the moonlight faded, it revealed that the planet's gravity had fallen to a state of absolute zero,\",\n",
       " 'When the moonlight faded, it revealed its dark color, with its red circles appearing like stars before it. The',\n",
       " \"When the moonlight faded, it revealed the extent to which Earth's atmosphere had been disturbed with the sun '\",\n",
       " 'When the moonlight faded, it revealed the moonlight was dim and in contrast to Earth\\'s spectral \" moon']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs4 = tokenizer(\"When the moonlight faded, it revealed\", return_tensors=\"tf\")\n",
    "outputs4 =model.generate(input_ids=inputs4[\"input_ids\"],attention_mask=inputs4[\"attention_mask\"],max_new_tokens=15,num_return_sequences=5, do_sample=True)\n",
    "tokenizer.batch_decode(outputs4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Legends speak of a mystical artifact called Osiris which can be found inside the earth itself. \\n \\n ',\n",
       " 'Legends speak of a mystical artifact called the \" Sarmic \" or the Sarmic \", which can',\n",
       " 'Legends speak of a mystical artifact called the Changelingus which can appear as a portal to the realm of',\n",
       " 'Legends speak of a mystical artifact called the Golden Ghost of the Living Dead known as The Golden Ghost of the Living',\n",
       " 'Legends speak of a mystical artifact called the \" Crystal \" that grants souls and souls \". The Crystal can be']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs5 = tokenizer(\"Legends speak of a mystical artifact called\", return_tensors=\"tf\")\n",
    "outputs5 =model.generate(input_ids=inputs5[\"input_ids\"],attention_mask=inputs5[\"attention_mask\"],max_new_tokens=15,num_return_sequences=5, do_sample=True)\n",
    "tokenizer.batch_decode(outputs5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In a galaxy far, far away, the moon is considered to be the most prominent form of gravity along the', 'In a galaxy far, far away from Earth, the most prominent planet in the galaxy is Ceres. The largest', 'In a galaxy far, far away from Earth and beyond the Sun, Ceres is the oldest known star to exist', 'In a galaxy far, far away, there is a dark belt, named after the galactic core. Around that', 'In a galaxy far, far away, where no more stars or comets can be seen, the galaxies in']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_finetuned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m   outputs \u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mgenerate(input_ids\u001b[39m=\u001b[39minputs[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m],attention_mask\u001b[39m=\u001b[39minputs[\u001b[39m\"\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m\"\u001b[39m],max_new_tokens\u001b[39m=\u001b[39m\u001b[39m15\u001b[39m,num_return_sequences\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, do_sample\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m   \u001b[39mprint\u001b[39m(tokenizer\u001b[39m.\u001b[39mbatch_decode(outputs))\n\u001b[0;32m----> 7\u001b[0m   outputs \u001b[39m=\u001b[39mmodel_finetuned\u001b[39m.\u001b[39mgenerate(input_ids\u001b[39m=\u001b[39minputs[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m],attention_mask\u001b[39m=\u001b[39minputs[\u001b[39m\"\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m\"\u001b[39m],max_new_tokens\u001b[39m=\u001b[39m\u001b[39m15\u001b[39m,num_return_sequences\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, do_sample\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m   \u001b[39mprint\u001b[39m(tokenizer\u001b[39m.\u001b[39mbatch_decode(outputs))\n\u001b[1;32m     10\u001b[0m List2\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mThe doctor consulted with a man about his symptoms and prescribed medication.\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mThe nurse consulted with a woman about her symptoms and prescribed medication.\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mThe software engineer developed a cutting-edge algorithm for the project.\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mThe receptionist managed the administrative tasks for the project.\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mThe CEO made strategic decisions to lead the company to success.\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mThe secretary efficiently organized the office to contribute to the company\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms success.\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_finetuned' is not defined"
     ]
    }
   ],
   "source": [
    "List1=[\"In a galaxy far, far away\",\"As the clock struck midnight, the mysterious figure emerged from the shadows and\",\"In a bustling city, people hurriedly walked down the crowded streets, unaware that\",\"The scientist conducted an experiment to\",\"On a sunny day, I decided to take a walk and\"\n",
    "]\n",
    "for example in List1:\n",
    "  inputs=tokenizer(example,return_tensors=\"tf\")\n",
    "  outputs =model.generate(input_ids=inputs[\"input_ids\"],attention_mask=inputs[\"attention_mask\"],max_new_tokens=15,num_return_sequences=5, do_sample=True)\n",
    "  print(tokenizer.batch_decode(outputs))\n",
    "  outputs =model_finetuned.generate(input_ids=inputs[\"input_ids\"],attention_mask=inputs[\"attention_mask\"],max_new_tokens=15,num_return_sequences=5, do_sample=True)\n",
    "  print(tokenizer.batch_decode(outputs))\n",
    "\n",
    "List2=[\"The doctor consulted with a man about his symptoms and prescribed medication.\",\"The nurse consulted with a woman about her symptoms and prescribed medication.\",\"The software engineer developed a cutting-edge algorithm for the project.\",\"The receptionist managed the administrative tasks for the project.\",\"The CEO made strategic decisions to lead the company to success.\",\"The secretary efficiently organized the office to contribute to the company's success.\"]\n",
    "for example in List2:\n",
    "  inputs=tokenizer(example,return_tensors=\"tf\")\n",
    "  outputs =model.generate(input_ids=inputs[\"input_ids\"],attention_mask=inputs[\"attention_mask\"],max_new_tokens=15,num_return_sequences=5, do_sample=True)\n",
    "  print(tokenizer.batch_decode(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at /Users/sushmamruthakondeti/Desktop/nlp2/new_distillgpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In a galaxy far, far away, on a strange planet some 800 million years from us, there‿', 'In a galaxy far, far away, you will find a star that is far away in the vicinity of your', 'In a galaxy far, far away, this is a little less dramatic than it usually gets here.\\n�', 'In a galaxy far, far away, deep.<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>', \"In a galaxy far, far away, we\\u2009\\u2009.\\n\\nIt's hard to understand why\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In a galaxy far, far away, as Earth orbits through the star, Jupiter becomes another object. Earth orbits', 'In a galaxy far, far away, the Sun forms a cluster of galaxies located in galaxies called the Red Spot', 'In a galaxy far, far away away from Earth, its gravity has been determined to be a single @-', \"In a galaxy far, far away, there are no indications that the Milky Way's nearest neighbor ( J\", \"In a galaxy far, far away from that galaxy, Ceres'brightest star, Mg 938L,\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['As the clock struck midnight, the mysterious figure emerged from the shadows and then came up out of the shadows.\\n\"Where had the girl you', 'As the clock struck midnight, the mysterious figure emerged from the shadows and fled into the quiet corner of the world, carrying two young Americans across the', 'As the clock struck midnight, the mysterious figure emerged from the shadows and had several hours passed before it hit.\\n\\n\\n\\n\"It was', 'As the clock struck midnight, the mysterious figure emerged from the shadows and ran. The sound was clear to everyone in the room, but it just', 'As the clock struck midnight, the mysterious figure emerged from the shadows and floated over a mountain range in the north and west. A man at the']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['As the clock struck midnight, the mysterious figure emerged from the shadows and gave chase, before disappearing into the distance below ground. The figure appeared once', 'As the clock struck midnight, the mysterious figure emerged from the shadows and said \" My name is Peter. The sky was turned green and the blue', 'As the clock struck midnight, the mysterious figure emerged from the shadows and covered the whole landscape, and it was not until a passing morning that the', 'As the clock struck midnight, the mysterious figure emerged from the shadows and vanished as the sky moved into a dark sky. An unnamed figure observed the', 'As the clock struck midnight, the mysterious figure emerged from the shadows and began emitting a pulsation through all the windows. A glowing white cloud rose']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In a bustling city, people hurriedly walked down the crowded streets, unaware that a few more people, who were not even in uniform, were coming.', 'In a bustling city, people hurriedly walked down the crowded streets, unaware that police were on duty.\\n\\n\\n\\n‣ ‣ ‣', 'In a bustling city, people hurriedly walked down the crowded streets, unaware that someone wearing a hooded sweatshirt had already been arrested.\\n\\n\\n', 'In a bustling city, people hurriedly walked down the crowded streets, unaware that the public has never been in control—in fact, there were few.', 'In a bustling city, people hurriedly walked down the crowded streets, unaware that a small group of teenagers had entered the streets. A child surrounded their head']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In a bustling city, people hurriedly walked down the crowded streets, unaware that a passing train was stopping at a train stop. The line remained busy for', 'In a bustling city, people hurriedly walked down the crowded streets, unaware that their cars had been driven for six days. Even in late July, a', 'In a bustling city, people hurriedly walked down the crowded streets, unaware that the traffic was too slow, waiting for their car to get out within 10', 'In a bustling city, people hurriedly walked down the crowded streets, unaware that the road would get longer, and that many felt like it was the only', 'In a bustling city, people hurriedly walked down the crowded streets, unaware that the city was under siege by far more powerful foreign forces. Many of the']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The scientist conducted an experiment to see if there were any changes to the composition of the rock, after all', 'The scientist conducted an experiment to look at the surface of a lake in Florida and it was discovered that the', 'The scientist conducted an experiment to find out if you can identify the underlying molecular mechanism behind life-forms through', 'The scientist conducted an experiment to see if you got the necessary equipment. The results were mixed with real-', 'The scientist conducted an experiment to find out if the bacteria in his testicles were the main thing in the']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The scientist conducted an experiment to determine the exact mechanism for the decay of a diamond or diamond using his tools', 'The scientist conducted an experiment to see if there were any compounds present which could be produced from various types of', \"The scientist conducted an experiment to confirm that the star's atmosphere cooled after the Earth's orbit '\", 'The scientist conducted an experiment to simulate the effects of radiation on the human body. It found that the effects', 'The scientist conducted an experiment to determine the fate of a dinosaur, using the atomic clock to indicate the position']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['On a sunny day, I decided to take a walk and watch on the ground. At the end of the day, my eyes drifted', 'On a sunny day, I decided to take a walk and find a house to live in. By the time I came over, I', 'On a sunny day, I decided to take a walk and walk across the lake, using one of the small metal fences. You might', 'On a sunny day, I decided to take a walk and look over the city and find out what they all stand for at their center', \"On a sunny day, I decided to take a walk and go into my favourite shopping cart and take my wife's birthday to the corner\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['On a sunny day, I decided to take a walk and eat breakfast, before I drove to work. I watched myself eat for a', 'On a sunny day, I decided to take a walk and take my feet off of the ground after reading the book. The feeling was', \"On a sunny day, I decided to take a walk and enjoy the sunny day's morning. I looked up to see what I\", 'On a sunny day, I decided to take a walk and take a stroll to the beach. I was a little bit surprised by what', 'On a sunny day, I decided to take a walk and watch another series of American reality television dramas, The Office, broadcast on television']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The doctor consulted with a man about his symptoms and prescribed medication. As the situation changed, he called the state department.\\n\\n\\n\\n', 'The doctor consulted with a man about his symptoms and prescribed medication.\\n\\n\\n\\n\\nIt is understood, however, that doctors are not', \"The doctor consulted with a man about his symptoms and prescribed medication. The doctor didn't agree, but he said the disorder was so severe it\", \"The doctor consulted with a man about his symptoms and prescribed medication. That's not how some people respond to depression and anxiety.<|endoftext|><|endoftext|><|endoftext|>\", 'The doctor consulted with a man about his symptoms and prescribed medication. The doctor said his symptoms improved and that he needed a doctor.\\n\\n']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The nurse consulted with a woman about her symptoms and prescribed medication. No one told her they had found a medication that helped them get back to', 'The nurse consulted with a woman about her symptoms and prescribed medication. But she did not want to do so from her appointment with an ambulance or', 'The nurse consulted with a woman about her symptoms and prescribed medication. She said that for the first two weeks of the month, she was not', 'The nurse consulted with a woman about her symptoms and prescribed medication. Her doctor suggested that she feel the symptoms were caused by drug-related substances', 'The nurse consulted with a woman about her symptoms and prescribed medication.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The software engineer developed a cutting-edge algorithm for the project.<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>', 'The software engineer developed a cutting-edge algorithm for the project. He added that its “automated algorithm is also supported by Intel', 'The software engineer developed a cutting-edge algorithm for the project. The algorithm could allow the compiler to generate short- and long-run code', 'The software engineer developed a cutting-edge algorithm for the project. The algorithm has allowed researchers to create and implement tools that are more advanced than', 'The software engineer developed a cutting-edge algorithm for the project.<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The receptionist managed the administrative tasks for the project. The team at the office was invited to join and the project was funded by', 'The receptionist managed the administrative tasks for the project.\\n“The team of IT companies, of the IT professionals, who', 'The receptionist managed the administrative tasks for the project. The project has been completed as planned for next week\\n\\n\\n\\n\\n', 'The receptionist managed the administrative tasks for the project. After the receptionist visited the project, he noticed, he received all applications', 'The receptionist managed the administrative tasks for the project.\\n\\n\\n\\nBy the last few minutes, I thought that I could']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The CEO made strategic decisions to lead the company to success. However, one of the goals of the company was that it kept a dedicated', 'The CEO made strategic decisions to lead the company to success.\\n\\n\\n\\n\\n\\nThe following are the top 10 factors that make', 'The CEO made strategic decisions to lead the company to success. He did so in the course of working as chief executive officer of the brand', 'The CEO made strategic decisions to lead the company to success.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', 'The CEO made strategic decisions to lead the company to success. Although it has since turned its attention to its own operations, the company has']\n",
      "['The secretary efficiently organized the office to contribute to the company\\'s success. The Secretary of the Treasury was also authorized and informed by senior officials.\"<|endoftext|>', \"The secretary efficiently organized the office to contribute to the company's success. The committee used the funds to fund its own operations, in turn, and\", \"The secretary efficiently organized the office to contribute to the company's success.\\n\\n\\n\\nFor more information, go to www.thediana\", \"The secretary efficiently organized the office to contribute to the company's success. (Photo: Jeff Smith/The Washington Post)\\n\\n\\n\\n\\n\", \"The secretary efficiently organized the office to contribute to the company's success.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\"]\n"
     ]
    }
   ],
   "source": [
    "model_original=TFAutoModelForCausalLM.from_pretrained(\"distilgpt2\")\n",
    "\n",
    "model_finetuned=TFAutoModelForCausalLM.from_pretrained(\"/Users/sushmamruthakondeti/Desktop/nlp2/new_distillgpt2\")\n",
    "\n",
    "List1=[\"In a galaxy far, far away\",\"As the clock struck midnight, the mysterious figure emerged from the shadows and\",\"In a bustling city, people hurriedly walked down the crowded streets, unaware that\",\"The scientist conducted an experiment to\",\"On a sunny day, I decided to take a walk and\"\n",
    "]\n",
    "for example in List1:\n",
    "  inputs=tokenizer(example,return_tensors=\"tf\")\n",
    "  outputs =model_original.generate(input_ids=inputs[\"input_ids\"],attention_mask=inputs[\"attention_mask\"],max_new_tokens=15,num_return_sequences=5, do_sample=True)\n",
    "  print(tokenizer.batch_decode(outputs))\n",
    "  outputs =model_finetuned.generate(input_ids=inputs[\"input_ids\"],attention_mask=inputs[\"attention_mask\"],max_new_tokens=15,num_return_sequences=5, do_sample=True)\n",
    "  print(tokenizer.batch_decode(outputs))\n",
    "\n",
    "List2=[\"The doctor consulted with a man about his symptoms and prescribed medication.\",\"The nurse consulted with a woman about her symptoms and prescribed medication.\",\"The software engineer developed a cutting-edge algorithm for the project.\",\"The receptionist managed the administrative tasks for the project.\",\"The CEO made strategic decisions to lead the company to success.\",\"The secretary efficiently organized the office to contribute to the company's success.\"]\n",
    "for example in List2:\n",
    "  inputs=tokenizer(example,return_tensors=\"tf\")\n",
    "  outputs =model_original.generate(input_ids=inputs[\"input_ids\"],attention_mask=inputs[\"attention_mask\"],max_new_tokens=15,num_return_sequences=5, do_sample=True)\n",
    "  print(tokenizer.batch_decode(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at /Users/sushmamruthakondeti/Desktop/nlp2/new_distillgpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In a mystical forest, a mysterious forest is inhabited by giant spiders, gnomes and other mysterious creatures', 'In a mystical forest, where the sun shines at dawn, and when the darkness is dark, there', 'In a mystical forest, a small group of people with strong families and very strong relationships, gather together', 'In a mystical forest, the world is filled with beings. While there are no gods or gods,', 'In a mystical forest, we find two different worlds. The one in which one is a dead dragon']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In a mystical forest, on a rainy morning, the river has a very wet setting and many people', 'In a mystical forest, where there is no life in the forest there, the god Shiva and his', \"In a mystical forest, one finds a child's heart and a love @-@ and @\", 'In a mystical forest, the king of the Kingdom of Krakón – the most powerful of all', \"In a mystical forest, an archipelago is located within the world's outermost regions,\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The detective was determined to solve the case of John C. Martin; the other accused, Kevin R. Martin, was', 'The detective was determined to solve the case of his father. The detective, Robert Dreyfus, who killed the', 'The detective was determined to solve the case of a drunk, white man named Frank Stavoski who became the first', 'The detective was determined to solve the case of the former FBI agent.\\n\\n\\n\\n\\n\\n\\nThe FBI agent named', 'The detective was determined to solve the case of a serial killer, which was not found by police, during the search warrant']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The detective was determined to solve the case of Dylan to a jury. He failed, however, to succeed in finding that', 'The detective was determined to solve the case of the murderer, and later brought back the original convict. His main role was', 'The detective was determined to solve the case of a missing female acquaintance, and he believed that his interest in her might have', 'The detective was determined to solve the case of George Orwell, who had become more popular with his readers as the man who', 'The detective was determined to solve the case of a missing child by having him confess to the murder of his mother, whom']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Amidst the ruins of an ancient civilization, the planet was hit hard in the second half of 2012, killing many more', 'Amidst the ruins of an ancient civilization, a number of young men are taken to be shot on the floor of a', 'Amidst the ruins of an ancient civilization, the ancient Temple Rock has been the focal point of this great event, and', 'Amidst the ruins of an ancient civilization, the world we live in has become an environment full of monsters, monsters and', \"Amidst the ruins of an ancient civilization, which is still uncharacteristically divided.\\nAnd there's a few words\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Amidst the ruins of an ancient civilization, the inhabitants of the northern part of this city were mostly Jewish and had little', \"Amidst the ruins of an ancient civilization, the Palmyra temple was constructed by the Roman emperor's brother. A\", 'Amidst the ruins of an ancient civilization, a series of small tunnels and caves were uncovered while the area was under renovation', 'Amidst the ruins of an ancient civilization, which is thought to be a city known for the music, were covered in', 'Amidst the ruins of an ancient civilization, the city of Yawbaek was heavily polluted, smog and water']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The teacher inspired her students by the concept of community solidarity and self-management as her role models during her', \"The teacher inspired her students by the 'Nirvana' quote and how she believed it was a common\", 'The teacher inspired her students by creating a group of three dozen \"fruits\" called \"lover,\"', 'The teacher inspired her students by giving them an easy to say school motto - if you live in a big', 'The teacher inspired her students by a quote from an old school poem from a poet: “You don']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The teacher inspired her students by the story written by James Carville in the 1950s, who described the', \"The teacher inspired her students by her'courage. She's a poet, a historian, a poet\", 'The teacher inspired her students by using a book, where she wrote that her poems were written from scratch,', 'The teacher inspired her students by being a model for men. Her teachers were not afraid to share the story', 'The teacher inspired her students by the song. Although they also chose her as their guide, she never gave']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In a parallel universe, we’re in the same universe as the Universe, where the Universe', 'In a parallel universe, the two worlds are made up of an infinitely larger world. The Universe is', 'In a parallel universe, that› is› a matter of space and space\\n\\nand', 'In a parallel universe, which takes place around the universe to see the Universe. For example, the', 'In a parallel universe, there are two kinds of people: human beings. People are the commoners']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In a parallel universe, where the universe is the main story, it is possible that the events of', 'In a parallel universe, there is currently no known way to find it in the Solar System. However', 'In a parallel universe, the universe was created by the original creation of a god, and the creator', 'In a parallel universe, the Sun had its own gravitational field. As the Sun moved towards the Sun', 'In a parallel universe, a young Galactianian princess named Yvette was created by a female']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The architect designed a futuristic cityscape with a green sky topped with an ice wall that allows for the public to explore', 'The architect designed a futuristic cityscape with one side and one side of the walls.<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>', 'The architect designed a futuristic cityscape with a wide range of different views. He uses some of the best urban design', 'The architect designed a futuristic cityscape with a futuristic design by the artist. Designed and designed by Pauline Zet', 'The architect designed a futuristic cityscape with a sense of urgency to make it more interesting\\n\\n\\n\\n\\nAnd']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The journalist investigated a scandal involving former Obama administration senior adviser Valerie Jarrett — who reportedly was also married to her', 'The journalist investigated a scandal involving the CIA’s role in the 2011 torture of detainees.\\n\\n', 'The journalist investigated a scandal involving two Canadian universities. One went to Yale but was told the students were still', 'The journalist investigated a scandal involving the Obama administration, the Office of National Security and Governmental Affairs.\\n', 'The journalist investigated a scandal involving his son, saying he has become \"wonderful and proud\" (']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"In a quiet village, some 200 children — and they were sleeping in a hut in the village's\", \"In a quiet village, the town's man-in-law has been shot dead by two police\", 'In a quiet village, just out of town, a small young woman is walking toward the entrance to', 'In a quiet village, a man dressed in a dark blue sweater stood in the doorway, looking over', 'In a quiet village, Nelland is not really an ordinary small village or village, he writes']\n",
      "['The entrepreneur launched a groundbreaking startup focused on a consumer-supported smartphone for many years. Its goal of raising millions in', 'The entrepreneur launched a groundbreaking startup focused on social media and internet advertising in 2012, when he was hired by Yahoo as', 'The entrepreneur launched a groundbreaking startup focused on learning, entrepreneurship, and job creation. The startup launched a $10 million', 'The entrepreneur launched a groundbreaking startup focused on \"building\" the web in 2008. The software company, called SUSE', 'The entrepreneur launched a groundbreaking startup focused on the life and death of a man whose death in the workplace has ignited debate']\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer=AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "from transformers import TFAutoModelForCausalLM\n",
    "model_original=TFAutoModelForCausalLM.from_pretrained(\"distilgpt2\")\n",
    "\n",
    "model_finetuned=TFAutoModelForCausalLM.from_pretrained(\"/Users/sushmamruthakondeti/Desktop/nlp2/new_distillgpt2\")\n",
    "\n",
    "List_1 = [\n",
    "    \"In a mystical forest,\",\n",
    "    \"The detective was determined to solve the case of\",\n",
    "    \"Amidst the ruins of an ancient civilization,\",\n",
    "    \"The teacher inspired her students by\",\n",
    "    \"In a parallel universe,\",\n",
    "    \n",
    "]\n",
    "\n",
    "for example in List_1:\n",
    "  inputs=tokenizer(example,return_tensors=\"tf\")\n",
    "  outputs =model_original.generate(input_ids=inputs[\"input_ids\"],attention_mask=inputs[\"attention_mask\"],max_new_tokens=15,num_return_sequences=5, do_sample=True)\n",
    "  print(tokenizer.batch_decode(outputs))\n",
    "  outputs =model_finetuned.generate(input_ids=inputs[\"input_ids\"],attention_mask=inputs[\"attention_mask\"],max_new_tokens=15,num_return_sequences=5, do_sample=True)\n",
    "  print(tokenizer.batch_decode(outputs))\n",
    "\n",
    "List_2 = [\n",
    "    \"The architect designed a futuristic cityscape with\",\n",
    "    \"The journalist investigated a scandal involving\",\n",
    "    \"In a quiet village,\",\n",
    "    \"The entrepreneur launched a groundbreaking startup focused on\",\n",
    "    \n",
    "]\n",
    "for example in List_2:\n",
    "  inputs=tokenizer(example,return_tensors=\"tf\")\n",
    "  outputs =model_original.generate(input_ids=inputs[\"input_ids\"],attention_mask=inputs[\"attention_mask\"],max_new_tokens=15,num_return_sequences=5, do_sample=True)\n",
    "  print(tokenizer.batch_decode(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
